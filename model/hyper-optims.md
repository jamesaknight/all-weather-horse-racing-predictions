# Attempted Hyper-parameter optimisations

## Optimisers

| Stochastic Gradient Descent | Adam | RMSProp | ADAgrad | AdamW |
|:-:|:-:|:-:|:-:|:-:|
| lr = 0.001, momentum 0.6-0.9 |lr = 0.001| alpha 0.99| lr 0.01| decay 0.01|

## Loss function

Huber - delta 1
MSE

## Layout

various combinations of 2^n node for hidden layers
hidden players 2-4

## Activation

leaky relu
relu

## Masking
masked huber does not work