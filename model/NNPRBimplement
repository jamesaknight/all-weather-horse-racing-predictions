import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import numpy as np

# Load the dataset
data = pd.read_csv('AW_Processed_Normalized.csv')

# Filter rows where HCP == 1 (Handicap races only)
data = data[data['HCP'] == 1]

# Select specific features for training
race_level_features = [
    'Distance (y)', 'Class', 'Course_Chelmsford City', 'Course_Kempton', 
    'Course_Lingfield', 'Course_Newcastle', 'Course_Southwell', 
    'Course_Wolverhampton', 'PPI'
]
horse_level_features = [
    'Draw', 'Draw IV', 'Age', 'Weight (pounds)', 'DSLR', 'Sex Abbrev', 
    'Equip Change', 'PRC Average Ratio', 'PRC Last Run Ratio', 
    'PRC 2nd Last Run Ratio', 'PRC 3rd Last Run Ratio', 'Trn Stats Ratio', 
    'Jky Stats Ratio', 'TrnJky Stats Ratio', 'Hrs Stats Ratio', 
    'HA Last 1 Year Speed Rating Ratio', 'MR Career Speed Rating Ratio', 
    'MR Last 1 Year Speed Rating Ratio', 'MR Last 3 Runs Speed Rating Ratio', 
    'LTO Speed Rating Ratio', '2nd LTO Speed Rating Ratio', 
    '3rd LTO Speed Rating Ratio', '4th LTOt Speed Rating Ratio'
]
target_variable = 'PRB'

# Additional columns to include in the output
output_columns = ['Race Time', 'Horse']

# Combine race-level and horse-level features
selected_features = race_level_features + horse_level_features

# Rows where PRB is blank (unseen races)
unseen_races = data[data['PRB'].isna()]

# Ensure selected features are in the dataset
X_unseen = unseen_races[selected_features]  # Features for unseen races
output_unseen = unseen_races[output_columns]  # Race Time and Horse for unseen races

# Ensure features are numeric and convert to NumPy arrays
X_unseen = X_unseen.apply(pd.to_numeric, errors='coerce').to_numpy().astype(np.float32)

# Define the neural network architecture
model = Sequential([
    Dense(128, activation='relu', input_shape=(X_unseen.shape[1],)),  # Input layer
    Dropout(0.3),  # Dropout to prevent overfitting
    Dense(64, activation='relu'),  # Hidden layer 1
    Dropout(0.3),
    Dense(32, activation='relu'),  # Hidden layer 2
    Dropout(0.2),
    Dense(1, activation='linear')  # Output layer for continuous target
])

# Compile the model
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Train-test split (for training purposes)
data = data[data['PRB'].notna()]  # Use rows where PRB is available for training
X = data[selected_features].apply(pd.to_numeric, errors='coerce').to_numpy().astype(np.float32)
y = data['PRB'].apply(pd.to_numeric, errors='coerce').to_numpy().astype(np.float32)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
history = model.fit(X_train, y_train, 
                    validation_split=0.2, 
                    epochs=100, 
                    batch_size=32, 
                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)],
                    verbose=1)

# Predict on unseen races
y_unseen_pred = model.predict(X_unseen)

# Add predictions to output_unseen
output_unseen['Predicted PRB'] = y_unseen_pred

# Save the predictions to a CSV file
output_unseen.to_csv('unseen_race_predictions.csv', index=False)

print("Predictions for unseen races saved to 'unseen_race_predictions.csv'")

# Normalize the predictions
# Function to normalize Predicted PRB values
def normalize_prb(df):
    # Calculate the number of runners (N) and sum of Predicted PRBs for each race
    df['N'] = df.groupby('Race Time')['Horse'].transform('count')
    df['Sum Predicted PRBs'] = df.groupby('Race Time')['Predicted PRB'].transform('sum')

    # Apply the normalization formula
    df['Normalized PPRB'] = df['Predicted PRB'] * (df['N'] / 2) / df['Sum Predicted PRBs']

    # Round Normalized PPRB to 2 decimal places
    df['Normalized PPRB'] = df['Normalized PPRB'].round(2)

    return df

# Load the predictions file
file_path = 'unseen_race_predictions.csv'
data = pd.read_csv(file_path)

# Normalize the data
normalized_data = normalize_prb(data)

# Save the normalized data to a new CSV file
output_path = 'normalized_race_predictions.csv'
normalized_data.to_csv(output_path, index=False)

print(f"Normalized predictions saved to '{output_path}'")

